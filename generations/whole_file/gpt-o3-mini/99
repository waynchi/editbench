from dataclasses import dataclass
import numpy as np
norm = np.random.normal



@dataclass
class NeuralNetwork:
  # это тоже самое что __init__
  inp: ... # input  nodes (число нейронов в инпуте, то есть число инпутов)
  hid: ... # hidden nodes (число нейронов в промежутке, то есть сколько чисел обрабатываем в промежутке)
  out: ... # output nodes (число аутпутных нейронов, то есть чисел в аутпуте)
  lr:  ... # learning rate (коэффициент сглаживания альфа)
  act: ... # activation function (зависимость вывода нейрона от ввода в нейрон)
  epo: ... # epochs (число эпох нейронов)

  # метод dataclass
  def __post_init__(self):  # generate weights
    # Инициализация весов с использованием стандартного отклонения 1/sqrt(число входов) для wih,
    # и 1/sqrt(число скрытых нейронов) для who, что является более корректным подходом.
    self.wih = norm(0., 1. / np.sqrt(self.inp), (self.hid, self.inp))
    self.who = norm(0., 1. / np.sqrt(self.hid), (self.out, self.hid))

  def train(self, x, y):
    x = np.array(x, ndmin=2).T
    y = np.array(y, ndmin=2).T

    ho = self.act(self.wih @ x)  # hidden outputs
    fo = self.act(self.who @ ho) # final  outputs
    oe = y - fo            # output errors
    he = self.who.T @ oe      # hidden errors
    self.who += self.lr * (oe * fo * (1. - fo)) @ ho.T
    self.wih += self.lr * (he * ho * (1. - ho)) @ x.T

  def query(self, x):
    x = np.array(x, ndmin=2).T
    return self.act(self.who @ self.act(self.wih @ x))

  def fit(self, X, y):
    for e in range(self.epo):
      for i in range(len(y)):
        self.train(X[i], y[i])

  def predict(self, X):
    return np.array([np.argmax(self.query(x)) for x in X])

  def score(self, X, y):
    y = np.array([np.argmax(i) for i in y])
    return (self.predict(X) == y).mean()