import numpy as np


def linear_regression_gradient_descent(
    X: np.ndarray, y: np.ndarray, alpha: float, iterations: int
) -> np.ndarray:
    # Twój kod tutaj, upewnij się, że zaokrąglasz
    m, n = X.shape
    theta = np.zeros((n, 1))
    if y.ndim == 1:
        y = y.reshape(-1, 1)

    for _ in range(iterations):
        gradient = (1/m) * X.T @ (X @ theta - y)
        theta -= alpha * gradient
        theta = np.round(theta, 2)

    return theta


print(
    linear_regression_gradient_descent(
        np.array([[1, 1], [1, 2], [1, 3]]), np.array([1, 2, 3]), 0.01, 1000
    )
)